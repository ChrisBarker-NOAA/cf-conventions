==  NetCDF Files and Components 

The components of a netCDF file are described in section 2 of the NUG <<NUG>>.
In this section we describe conventions associated with filenames and the basic components of a netCDF file.
We also introduce new attributes for describing the contents of a file.

=== Filename

NetCDF files should have the file name extension "**`.nc`**".

=== Data Types

// TODO: Check, should this be a bullet list?
Data variables must be one of the following data types: **`string`**, **`char`**, **`byte`**, **`unsigned byte`**, **`short`**, **`unsigned short`**, **`int`**, **`unsigned int`**, **`int64`**, **`unsigned int64`**, **`float`** or **`real`**, and **`double`** (which are all the link:$$https://docs.unidata.ucar.edu/nug/current/md_types.html$$[netCDF external data types] supported by netCDF-4).
The **`string`** type is only available in files using the netCDF version 4 (netCDF-4) format.
The **`char`** and **`string`** types are not intended for numeric data.
One byte numeric data should be stored using the **`byte`** or **`unsigned byte`** data types.
It is possible to treat the **`byte`** and **`short`** types as unsigned by using the NUG convention of indicating the unsigned range using the **`valid_min`**, **`valid_max`**, or **`valid_range`** attributes.
In many situations, any integer type may be used.
When the phrase "integer type" is used in this document, it should be understood to mean **`byte`**, **`unsigned byte`**, **`short`**, **`unsigned short`**, **`int`**, **`unsigned int`**, **`int64`**, or **`unsigned int64`**.

Strings in variables may be represented one of two ways - as atomic strings or as character arrays.
An n-dimensional array of strings may be implemented as a variable of type **`string`** with n dimensions, or as a variable of type **`char`** with n+1 dimensions where the last (most rapidly varying) dimension is large enough to contain the longest string in the variable.
For example, a character array variable of strings containing the names of the months would be dimensioned (12,9) in order to accommodate "September", the month with the longest name.
The other strings, such as "May", should be padded with trailing NULL or space characters so that every array element is filled.
If the atomic string option is chosen, each element of the variable can be assigned a string with a different length.
The CDL example below shows one variable of each type.

[[char-and-string-variables-ex]]
[caption="Example 2.1. "]
.String Variable Representations
====
----
dimensions:
  strings = 30 ;
  strlen = 10 ;
variables:
  char char_variable(strings,strlen) ;
    char_variable:long_name = "strings of type char" ;
  string str_variable(strings) ;
    str_variable:long_name = "strings of type string" ;
----
====

The examples in this document that use string-valued variables alternate between these two forms.

=== Naming Conventions

Variable, dimension, attribute and group names should begin with a letter and be composed of letters, digits, and underscores.
By the word _letters_ we mean the standard ASCII letters uppercase `A` to `Z` and lowercase `a` to `z`.
By the word _digits_ we mean the standard ASCII digits `0` to `9`, and similarly _underscores_ means the standard ASCII underscore `_`.
Note that this is in conformance with the COARDS conventions, but is more restrictive than the netCDF interface which allows almost all Unicode characters encoded as multibyte UTF-8 characters (link:$$https://docs.unidata.ucar.edu/nug/current/file_format_specifications.html$$[NUG Appendix B]).
The netCDF interface also allows leading underscores in names, but the NUG states that this is reserved for system use.
ASCII period (.) and ASCII hyphen (-) are also allowed in attribute names only.

Case is significant in netCDF names, but it is recommended that names should not be distinguished purely by case, i.e., if case is disregarded, no two names should be the same.
It is also recommended that names should be obviously meaningful, if possible, as this renders the file more effectively self-describing.

This convention does not standardize any variable or dimension names.
Attribute names and their contents, where standardized, are given in English in this document and should appear in English in conforming netCDF files for the sake of portability.
Languages other than English are permitted for variables, dimensions, and non-standardized attributes.
The content of some standardized attributes are string values that are not standardized, and thus are not required to be in English.
For example, a description of what a variable represents may be given in a non-English language using the **`long_name`** attribute (see <<long-name>>) whose contents are not standardized, but a description given by the **`standard_name`** attribute (see <<standard-name>>) must be taken from the standard name table which is in English.

[[dimensions]]
=== Dimensions

A variable may have any number of dimensions, including zero, and the dimensions must all have different names.
__COARDS strongly recommends limiting the number of dimensions to four, but we wish to allow greater flexibility__.
The dimensions of the variable define the axes of the quantity it contains.
Dimensions other than those of space and time may be included.
Several examples can be found in this document.
Under certain circumstances, one may need more than one dimension in a particular quantity.
For instance, a variable containing a two-dimensional probability density function might correlate the temperature at two different vertical levels, and hence would have temperature on both axes.

If any or all of the dimensions of a variable have the interpretations of "date or time" (**`T`**), "height or depth" (**`Z`**), "latitude" (**`Y`**), or "longitude" (**`X`**) then we recommend, but do not require (see <<coards-relationship>>), those dimensions to appear in the relative order **`T`**, then **`Z`**, then **`Y`**, then **`X`** in the CDL definition corresponding to the file.
All other dimensions should, whenever possible, be placed to the left of the spatiotemporal dimensions.

Dimensions may be of any size, including unity.
When a single value of some coordinate applies to all the values in a variable, the recommended means of attaching this information to the variable is by use of a dimension of size unity with a one-element coordinate variable.
It is also acceptable to use a scalar coordinate variable which eliminates the need for an associated size one dimension in the data variable.
The advantage of using either a coordinate variable or an auxiliary coordinate variable is that all its attributes can be used to describe the single-valued quantity, including boundaries.
For example, a variable containing data for temperature at 1.5 m above the ground has a single-valued coordinate supplying a height of 1.5 m, and a time-mean quantity has a single-valued time coordinate with an associated boundary variable to record the start and end of the averaging period.

[[variables]]
=== Variables

This convention does not standardize variable names.

NetCDF variables that contain coordinate data are referred to as __coordinate variables__, __auxiliary coordinate variables__, __scalar coordinate variables__, or __multidimensional coordinate variables__.

[[missing-data, Section 2.5.1, "Missing data, valid and actual range of data"]]
==== Missing data, valid and actual range of data

The NUG conventions
(link:$$https://www.unidata.ucar.edu/software/netcdf/docs/attribute_conventions.html$$[NUG Appendix A, Attribute Conventions])
provide the **`_FillValue`**, **`missing_value`**, **`valid_min`**, **`valid_max`**, and **`valid_range`** attributes to indicate missing data.
Missing data is allowed in data variables and auxiliary coordinate variables.
Generic applications should treat the data as missing where any auxiliary coordinate variables have missing values; special-purpose applications might be able to make use of the data.
Missing data is not allowed in coordinate variables.

The NUG conventions for missing data changed significantly between version 2.3 and version 2.4.
Since version 2.4 the NUG defines missing data as all values outside of the **`valid_range`**, and specifies how the **`valid_range`** should be defined from the **`_FillValue`** (which has library specified default values) if it hasn't been explicitly specified.
If only one missing value is needed for a variable then we recommend  that this value be specified using the **`_FillValue`** attribute.
Doing this guarantees that the missing value will be recognized by generic applications that follow either the before or after version 2.4 conventions.

The scalar attribute with the name **`_FillValue`** and of the same type as its variable is recognized by the netCDF library as the value used to pre-fill disk space allocated to the variable.
This value is considered to be a special value that indicates undefined or missing data, and is returned when reading values that were not written.
The **`_FillValue`** should be outside the range specified by **`valid_range`** (if used) for a variable.
The netCDF library defines a default fill value for each data type (See the "Note on fill values" in link:$$https://www.unidata.ucar.edu/software/netcdf/docs/file_format_specifications.html#classic_format_spec$$[NUG Appendix B, File Format Specifications]).

The missing values of a variable with **`scale_factor`** and/or **`add_offset`** attributes (see <<packed-data>>) are interpreted relative to the variable's external values (a.k.a. the packed values, the raw values, the values stored in the netCDF file), not the values that result after the scale and offset are applied.
Applications that process variables that have attributes to indicate both a transformation (via a scale and/or offset) and missing values should first check that a data value is valid, and then apply the transformation.
Note that values that are identified as missing should not be transformed.
Since the missing value is outside the valid range it is possible that applying a transformation to it could result in an invalid operation.
For example, the default **`_FillValue`** is very close to the maximum representable value of IEEE single precision floats, and multiplying it by 100 produces an "Infinity" (using single precision arithmetic).

This convention defines a two-element vector attribute **`actual_range`** for variables containing numeric data.
If the variable is packed using the **`scale_factor`** and **`add_offset`** attributes (see <<packed-data>>), the elements of the **`actual_range`** should have the type intended for the unpacked data.
The elements of **`actual_range`** must be exactly equal to the minimum and the maximum data values which occur in the variable (when unpacked if packing is used), and both must be within the **`valid_range`** if specified.
If the data is all missing or invalid, the **`actual_range`** attribute cannot be used.

=== Attributes

This standard describes many attributes (some mandatory, others optional), but a file may also contain non-standard attributes.
Such attributes do not represent a violation of this standard.
Application programs should ignore attributes that they do not recognise or which are irrelevant for their purposes.
Conventional attribute names should be used wherever applicable.
Non-standard names should be as meaningful as possible.
Before introducing an attribute, consideration should be given to whether the information would be better represented as a variable.
In general, if a proposed attribute requires ancillary data to describe it, is multidimensional, requires any of the defined netCDF dimensions to index its values, or requires a significant amount of storage, a variable should be used instead.
When this standard defines string attributes that may take various prescribed values, the possible values are generally given in lower case.
However, applications programs should not be sensitive to case in these attributes.
Several string attributes are defined by this standard to contain "blank-separated lists".
Consecutive words in such a list are separated by one or more adjacent spaces.
The list may begin and end with any number of spaces.
See <<attribute-appendix>> for a list of attributes described by this standard.

[[identification-of-conventions]]
==== Identification of Conventions

Files that follow this version of the CF Conventions must indicate this by setting the NUG defined global attribute **`Conventions`** to a string value that contains "**`CF-{current-version-as-attribute}`**".
The Conventions version number contained in that string can be used to find the web based versions of this document are from the link:$$https://cfconventions.org/$$[netCDF Conventions web page].
Subsequent versions of the CF Conventions will not make invalid a compliant usage of this or earlier versions of the CF terms and forms.

It is possible for a netCDF file to adhere to more than one set of conventions, even when there is no inheritance relationship among the conventions.
In this case, the value of the Conventions attribute may be a single text string containing a list of the convention names separated by blank space (recommended) or commas (if a convention name contains blanks).
This is the Unidata recommended syntax from NetCDF Users Guide, Appendix A.
If the string contains any commas, it is assumed to be a comma-separated list.

When CF is listed with other conventions, this asserts the same full compliance with CF requirements and interpretations as if CF was the sole convention.
It is the responsibility of the data-writer to ensure that all common metadata is used with consistent meaning between conventions.

The UGRID conventions, which are fully incorporated into the CF conventions, do not need to be included in the **`Conventions`** attribute.  

[[description-of-file-contents, Section 2.6.2, "Description of file contents"]]
==== Description of file contents

The following attributes are intended to provide information about where the data came from and what has been done to it.
This information is mainly for the benefit of human readers.
The attribute values are all character strings.
For readability in ncdump outputs it is recommended to embed newline characters into long strings to break them into lines.
For backwards compatibility with COARDS none of these global attributes is required.

The NUG defines **`title`** and **`history`** to be global attributes.
We wish to allow the newly defined attributes, i.e., **`institution`**, **`source`**, **`references`**, and **`comment`**, to be either global or assigned to individual variables.
When an attribute appears both globally and as a variable attribute, the variable's version has precedence.

**`title`**:: A succinct description of what is in the dataset.

**`institution`**:: Specifies where the original data was produced.

**`source`**:: The method of production of the original data.
If it was model-generated, **`source`** should name the model and its version, as specifically as could be useful.
If it is observational, **`source`** should characterize it (e.g., "**`surface observation`**" or "**`radiosonde`**").

**`history`**:: Provides an audit trail for modifications to the original data.
Well-behaved generic netCDF filters will automatically append their name and the parameters with which they were invoked to the global history attribute of an input netCDF file.
We recommend that each line begin with a timestamp indicating the date and time of day that the program was executed.

**`references`**:: Published or web-based references that describe the data or methods used to produce it.

**`comment`**:: Miscellaneous information about the data or methods used to produce it.

[[external-variables, Section 2.6.3, "External variables"]]
==== External Variables
The global **`external_variables`** attribute is a blank-separated list of the names of variables which are named by attributes in the file but which are not present in the file.
These variables are to be found in other files (called "external files") but CF does not provide conventions for identifying the files concerned.
The only attribute for which CF standardises the use of external variables is **`cell_measures`**.

[[groups, Section 2.7, "Groups"]]
=== Groups

Groups provide a powerful mechanism to structure data hierarchically.
This convention does not standardize group names.
It may be of benefit to name groups in such a way that human readers can interpret them.
However, files that conform to this standard shall not require software to interpret or decode information from group names.
References to out-of-group variable and dimensions shall be found by applying the scoping rules outlined below.

==== Scope

The scoping mechanism is in keeping with the following principal:

[quote, 'https://www.unidata.ucar.edu/software/netcdf/docs/groups.html[The NetCDF Data Model: Groups]']
"Dimensions are scoped such that they are visible to all child groups.
For example, you can define a dimension in the root group, and use its dimension id when defining a variable in a sub-group."

Any variable or dimension can be referred to, as long as it can be found with one of the following search strategies:

* Search by absolute path
* Search by relative path
* Search by proximity

These strategies are explained in detail in the following sections.

If any dimension of an out-of-group variable has the same name as a dimension of the referring variable, the two must be the same dimension (i.e. they must have the same netCDF dimension ID).

===== Search by absolute path

A variable or dimension specified with an absolute path (i.e., with a leading slash "/") is at the indicated location relative to the root group, as in a UNIX-style file convention.
For example, a `coordinates` attribute of `/g1/lat` refers to the `lat` variable in group `/g1`.

===== Search by relative path

As in a UNIX-style file convention, a variable or dimension specified with a relative path (i.e., containing a slash but not with a leading slash, e.g. `child/lat`) is at the location obtained by affixing the relative path to the absolute path of the referring attribute.
For example, a `coordinates` attribute of `g1/lat` refers to the `lat` variable in subgroup `g1` of the current (referring) group.
Upward path traversals from the current group are indicated with the UNIX convention.
For example, `../g1/lat` refers to the `lat` variable in the sibling group `g1` of the current (referring) group.

===== Search by proximity

A variable or dimension specified with no path (for example, `lat`) refers to the variable or dimension of that name, if there is one, in the referring group.
If not, the ancestors of the referring group are searched for it, starting from the direct ancestor and proceeding toward the root group, until it is found.

A special case exists for coordinate variables.
Because coordinate variables must share dimensions with the variables that reference them, the ancestor search is executed only until the local apex group is reached.
For coordinate variables that are not found in the referring group or its ancestors, a further strategy is provided, called lateral search.
The lateral search proceeds downwards from the local apex group width-wise through each level of groups until the sought coordinate is found.
The lateral search algorithm may only be used for NUG coordinate variables; it shall not be used for auxiliary coordinate variables.

[NOTE]
====
This use of the lateral search strategy to find them is discouraged.
They are allowed mainly for backwards-compatibility with existing datasets, and may be deprecated in future versions of the standard.
====

==== Application of attributes

The following attributes are optional for non-root groups.
They are allowed in order to provide additional provenance and description of the subsidiary data.
They do not override attributes from parent groups.

* `title`
* `history`

If these attributes are present, they may be applied additively to the parent attributes of the same name.
If a file containing groups is modified, the user or application need only update these attributes in the root group, rather than traversing all groups and updating all attributes that are found with the same name.
In the case of conflicts, the root group attribute takes precedence over per-group instances of these attributes.

The following attributes may only be used in the root group and shall not be duplicated or overridden in child groups:

* `Conventions`
* `external_variables`

Furthermore, per-variable attributes must be attached to the variables to which they refer.
They may not be attached to a group, even if all variables within that group use the same attribute and value.

If attributes are present within groups without being attached to a variable, these attributes apply to the group where they are defined, and to that group's descendants, but not to ancestor or sibling groups.
If a group attribute is defined in a parent group, and one of the child group redefines the same attribute, the definition within the child group applies for the child and all of its descendants.


[[aggregation-variables, Section 2.8, "Aggregation Variables"]]
=== Aggregation Variables

An __aggregation variable__ is a variable which has been formed by combining (i.e. aggregating) multiple __fragments__ that are generally stored in __fragment datasets__ that are external to the file containing the aggregation variable, i.e. the __aggregation file__.
A fragment is an array of data with sufficient metadata for it to be correctly interpreted in the context of the aggregation, as described by <<fragment-interpretation>>.
The aggregation variable does not contain any actual data, instead it contains instructions on how to create its __aggregated data__ in memory as an aggregation of the data from each fragment.

Aggregation provides the utility of being able to view, as a single entity, a dataset that has been partitioned across multiple other datasets, whilst  taking up very little extra space on disk (since the aggregation file contains no copies of the data in the fragments).
Fragment datasets may be CF-compliant or have any other format, thereby allowing an aggregation variable to act as a CF-compliant view of non-CF datasets.
Use cases for storing aggregations include, but are not limited to: data analysis, as it avoids the computational expense of deriving the aggregation at the time of analysis; archive curation, as the aggregation can act as a metadata-rich archive index; and model simulations, for combining output data that have been written to disk as multiple datasets decomposed in time and space.

An aggregation variable must be a scalar (i.e. it has no dimensions).
It acts as a container for all of the usual attributes that describe the data, with the addition of two special attributes: one that defines the _aggregated dimensions_, i.e. the dimensions of the aggregated data; and one that provides the instructions on how the aggregated data is to be created.
The data type of the aggregation variable must be the data type of the aggregated data, but the value of the aggregation variable's single element is immaterial.

Aggregation variables may be used as any kind of variable (data variable, coordinate variable, cell measures variable, etc.), but it is recommended that container variables whose data are immaterial (such as grid mapping variables) are not encoded as aggregation variables.

Any text applying to a variable in the CF conventions applies in exactly the same way to an aggregation variable in the same role; and any reference to the dimensions or data of a variable applies to the aggregated dimensions or aggregated data, respectively, of an aggregation variable.
For instance:

* The dimension of a coordinate variable of an aggregation data variable must be one of the aggregated dimensions of the aggregation data variable.

* The name of an aggregation coordinate variable (which is a scalar) must
be the same as the name of its single aggregated dimension (identified by its **`aggregated_dimensions`** attribute), just as the name of a coordinate variable (which is one-dimensional) must be the same as the name of its single
dimension.

The details of how to encode and decode aggregation variables are given in this section, with examples provided in <<appendix-aggregation-examples>>.


[[aggregated-dimensions-and-data, Section 2.8.1, "Aggregated Dimensions and Data"]]
==== Aggregated Dimensions and Data

The aggregated dimensions are stored with the aggregation variable's **`aggregated_dimensions`** attribute, and it is the presence of this attribute that identifies the variable as an aggregation variable.
The value of the **`aggregated_dimensions`** attribute is a blank-separated list of the aggregated dimension names given in the order which matches the dimensions of the aggregated data.
If the aggregated data is scalar then there are no aggregated dimensions and the **`aggregated_dimensions`** attribute must be an empty string.
The aggregated dimensions must exist as dimensions in the aggregation file.

The fragments which provide the aggregated data are conceptually organised into a __fragment array__ that has the same number of dimensions as the aggregated data.
Each dimension of the fragment array is called a __fragment array dimension__, and corresponds to the aggregated dimension with the same position in the aggregated data.
The size of a fragment array dimension is equal to the number of fragments that are needed to span its corresponding aggregated dimension.
See <<example-fragment-array>>.

The aggregated data are created by concatenating the canonical forms of the fragments' data (see <<fragment-interpretation>>) along each fragment array dimension, and in the order in which they appear in the fragment array.

[[example-fragment-array]]
[caption="Example 2.2. "]
.A schematic representation of a fragment array for aggregated data
====
[cols="a,a"]
|===============
| *Fragment array position `[0, 0, 0]`*

Fragment location: `file_A.nc` +
Fragment data shape: `(17, 91, 180)` +
`17` vertical levels  +
`[90, 0]` degrees north  +
`[0, 180)` degrees east | *Fragment array position `[0, 0, 1]`*

Fragment location: `file_B.nc` +
Fragment data shape: `(17, 91, 180)` +
`17` vertical levels +
`[90, 0]` degrees north +
`[180, 360)` degrees east

| *Fragment array position `[0, 1, 0]`*

Fragment location: `file_C.nc` +
Fragment data shape: `(17, 45, 180)` +
`17` vertical levels +
`(0, -45]` degrees north +
`[0, 180)` degrees east | *Fragment array position `[0, 1, 1]`*

Fragment location: `file_D.nc` +
Fragment data shape: `(17, 45, 180)` +
`17` vertical levels +
`(0, -45]` degrees north +
`[180, 360)` degrees east

| *Fragment array position `[0, 2, 0]`*

Fragment location: `file_E.nc` +
Fragment data shape: `(17, 45, 180)` +
`17` vertical levels +
`(-45, -90]` degrees north +
`[0, 180)` degrees east | *Fragment array position `[0, 2, 1]`*

Fragment location: `file_F.nc` +
Fragment data shape: `(17, 45, 180)` +
`17` vertical levels +
`(-45, -90]` degrees north +
`[180, 360)` degrees east
|===============
The fragments, stored in six fragment datasets, are arranged in a three-dimensional fragment array with shape `(1, 3, 2)`.
Each fragment spans the entirety of the Z dimension, but only a part of the Y-X plane, which has 1 degree resolution.
The fragments combine to create three-dimensional aggregated data that have global Z-Y-X coverage, with shape `(17, 181, 360)`.
The Z aggregated dimension is spanned by one fragment, the Y aggregated dimension is spanned by three fragments, and the X aggregated dimension is spanned by two fragments.
Note that, since this example is a schematic representation, the C or Fortran order of the dimensions is of no consequence.
See <<example-L.4>> for a CDL representation of this fragment array. 
====

The fragment array must be defined by an aggregation variable's **`aggregated_data`** attribute.
This attribute takes a string value comprising blank-separated elements of the form "__feature: variable__", where __feature__ is a case-sensitive keyword that identifies a feature of the fragment array, and __variable__ is a __fragment array variable__ which provides values for that feature. The features and their values unambiguously define the fragment array.
The order of elements in the **`aggregated_data`** attribute is not significant.

The features must comprise either all three of the `shape`, `location`, and `address` keywords; or else both of the `shape` and `value` keywords. No other combinations of keywords are allowed. These features are defined as follows:

// Turn off section numbering for a bit
:numbered!:

===== shape

The integer-valued `shape` fragment array variable defines the shape of each fragment's data in its canonical form (see <<fragment-interpretation>>).
In general, the `shape` fragment array variable is two-dimensional, with the size of the slower-varying dimension (i.e. the first dimension in CDL order, representing rows) being the number of fragment array dimensions, and the size of the more rapidly-varying dimension (i.e. the second dimension in CDL order, representing columns) being the size of the largest fragment array dimension.
The rows correspond to the fragment array dimensions in the same order, and each row provides the sizes of the fragments along its corresponding dimension of the fragment array, padded with missing values if there are fewer fragments than the number of columns.
The sum of non-missing values in a row must therefore equal the size of the corresponding aggregated dimension.
See <<example-L.4>>, which shows the `shape` fragment array variable for the fragment array described by <<example-fragment-array>>.
If the aggregated data is scalar then the `shape` fragment array variable must be a scalar and contain the value `1`.
See <<example-L.8>>.

===== location

The string-valued `location` fragment array variable defines the locations of fragment datasets.
In general its dimensions correspond to, and have the same sizes as, the fragment array dimensions in the same order as they appear in the conceptual fragment array.
A fragment dataset is located with a Uniform Resource Identifier (URI) <<URI>> that must be either an __absolute URI__ (a URI that begins with a scheme component followed by a `:` character, such as `\file://data/file.nc`, `\https://remote.host/data/file.nc`, `s3://remote.host/data/file.nc`, or `locally_meaningful_protocol://UID`), or else a __relative-path URI reference__ (a URI that is not an absolute URI and which does not begin with a `/` or `#` character, such as `file.nc`, `../file.nc`, or `data/file.nc`).
A relative-path URI reference is taken as being relative to the location of the aggregation file.
If the aggregation file is moved to another location, then a fragment dataset identified by an absolute URI will still be accessible, whereas a fragment dataset identified by a relative-path URI reference will also need be moved to preserve the relative reference.
Not all fragment dataset locations need be of the same URI type.
See <<example-L.1>> and <<example-L.2>>.

The `location` fragment array variable may have an extra trailing dimension that allows multiple versions of fragments to be specified.
Each version must contain equivalent information, so that any version that exists may be selected for use in the aggregated data.
This could be useful when it is known that a fragment could be stored in a number of locations, but it is not known which of them might exist at any given time.
For instance, when remotely stored and locally cached versions of the same fragment have been defined, an application program could choose to only retrieve the remote version if the local version does not exist.
Every fragment must have at least one version, but not all fragments need to have the same number of versions.
Where fragments have fewer versions than others, the trailing dimension must be padded with missing values.
See <<example-L.2>>.

A fragment dataset location may be defined with any number of string substitutions, each of which is provided by the `location` fragment array variable's **`substitutions`** attribute.
The **`substitutions`** attribute takes a string value comprising blank-separated elements of the form "__substitution: replacement__", where __substitution__ is a case-sensitive keyword that defines part of a `location` fragment array variable value which is to be replaced by __replacement__ in order to find the actual fragment dataset location.
A `location` fragment array variable value may include any subset of zero or more of the substitution keywords.
After replacements have been made, the fragment dataset location must be an absolute URI or a relative-path URI reference.
The substitution keyword must have the form `${\*}`, where `*` represents any number of any characters.
For instance, the fragment dataset location `\https://remote.host/data/file.nc` could be stored as `$\{path}file.nc`, in conjunction with `substitutions="$\{path}: \https://remote.host/data/"`.
The order of elements in the **`substitutions`** attribute is not significant, and the substitutions for a given fragment must be such that applying them in any order will result in the same fragment dataset location.
The use of substitutions can save space in the aggregation file; and in the event that the fragment locations need to be updated after the aggregation file has been created, it may be possible to achieve this by modifying the **`substitutions`** attribute rather than by changing the actual `location` fragment array variable values.
See <<example-L.3>>.

===== address

The `address` fragment array variable, that may have any data type, defines how to find each fragment within its fragment dataset, i.e. the address of the fragment.
In general it has the same dimensions in the same order as the `location` fragment array variable, and must contain a non-missing value corresponding to each fragment version.
However, if the `address` fragment array variable is a scalar, then its single value applies to all versions of all fragments.
For a netCDF fragment dataset, the address must be the string-valued netCDF variable name of the fragment.
Addresses for other fragment dataset formats are allowed, on the understanding that an application program may choose to ignore any values that it does not understand.
See <<example-L.1>> and <<example-L.6>>.

===== value

When the data values within a fragment are all the same, for each fragment, the `value` fragment array variable allows each fragment to be represented explicitly by its unique data value, rather than by reference to a fragment dataset.
The `value` fragment array variable dimensions correspond to, and have the same sizes as, the fragment array dimensions in the same order as they appear in the conceptual fragment array.
The `value` fragment array variable may have any data type, and contains each fragment's unique value.
A fragment that contains wholly missing data is specified by any missing value indicated by the aggregation variable.
See <<example-L.7>>, which uses an aggregation ancillary variable to make fragment dataset attributes available to an aggregation data variable.

// Turn section numbering back on
:numbered:


[[fragment-interpretation, Section 2.8.2 "Fragment Interpretation"]]
==== Fragment Interpretation

The data of a fragment must be converted to its __canonical form__ prior to being inserted into the aggregated data. The canonical form of a fragment's data is such that:

* The fragment's data, in its entirety, provide the values for a unique and contiguous part of the aggregated data.

* The fragment's data dimensions correspond to the aggregated dimensions in the same order.

* The fragment's data have the same units as the aggregation variable.

* The fragment's data have missing values as indicated by the aggregation variable.

* The fragment's data are not packed (i.e. not stored using a smaller data type than the original data).

* The fragment's data have the same data type as the aggregation variable.

The conversion of the fragment's data to its canonical form is carried out by the application program which is creating the aggregated data in memory. For fragment datasets, the application program may ignore any fragment metadata that are not needed for the conversion to the canonical form, as well as any other variables that might exist in the fragment dataset.
A combination of the following operations may be required to convert the fragment's data to its canonical form:

* If, and only if, the fragment's data has been explicitly defined by its unique value (as opposed to being defined by a fragment dataset), broadcasting that value across the shape of the canonical form of the fragment's data.

* Inserting missing size 1 dimensions into the fragment's data (e.g. as required when aggregating two-dimensional fragments into three-dimensional aggregated data).

* Transforming the fragment's data to have the same data type as the aggregated data.
Note that some transformations may result in a loss of information, such as could be the case when casting floating point numbers to integers.

* Transforming missing values in the fragment's data to a value indicated as missing by the aggregation variable.
Note that it is the responsibility of the creator of the aggregation file to ensure that all non-missing fragment data values do not coincide with any of the missing values indicated by the aggregation variable.

* Transforming the fragment's data to have the aggregation variable's units (e.g. as required when aggregating time fragments whose units have different reference date/times).

* Unpacking the fragment's data.
Note that if the aggregation variable indicates that the aggregated data values are packed (as determined by the attributes defined in <<packed-data>>), then the canonical fragment data values will represent packed values in the aggregated data, and so will be subject to the aggregation variable's unpacking.